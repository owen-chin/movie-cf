{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "movies_df = pd.read_csv(\"data/ml-latest-small/movies.csv\")\n",
    "ratings_df = pd.read_csv(\"data/ml-latest-small/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dict = movies_df.set_index('movieId')[\"title\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>193581</td>\n",
       "      <td>Black Butler: Book of the Atlantic (2017)</td>\n",
       "      <td>Action|Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>193583</td>\n",
       "      <td>No Game No Life: Zero (2017)</td>\n",
       "      <td>Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>193585</td>\n",
       "      <td>Flint (2017)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>193587</td>\n",
       "      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n",
       "      <td>Action|Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>193609</td>\n",
       "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9742 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                      title  \\\n",
       "0           1                           Toy Story (1995)   \n",
       "1           2                             Jumanji (1995)   \n",
       "2           3                    Grumpier Old Men (1995)   \n",
       "3           4                   Waiting to Exhale (1995)   \n",
       "4           5         Father of the Bride Part II (1995)   \n",
       "...       ...                                        ...   \n",
       "9737   193581  Black Butler: Book of the Atlantic (2017)   \n",
       "9738   193583               No Game No Life: Zero (2017)   \n",
       "9739   193585                               Flint (2017)   \n",
       "9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n",
       "9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n",
       "\n",
       "                                           genres  \n",
       "0     Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                      Adventure|Children|Fantasy  \n",
       "2                                  Comedy|Romance  \n",
       "3                            Comedy|Drama|Romance  \n",
       "4                                          Comedy  \n",
       "...                                           ...  \n",
       "9737              Action|Animation|Comedy|Fantasy  \n",
       "9738                     Animation|Comedy|Fantasy  \n",
       "9739                                        Drama  \n",
       "9740                             Action|Animation  \n",
       "9741                                       Comedy  \n",
       "\n",
       "[9742 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "4.0    26818\n",
       "3.0    20047\n",
       "5.0    13211\n",
       "3.5    13136\n",
       "4.5     8551\n",
       "2.0     7551\n",
       "2.5     5550\n",
       "1.0     2811\n",
       "1.5     1791\n",
       "0.5     1370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9742\n",
      "9724\n"
     ]
    }
   ],
   "source": [
    "print(movies_df.movieId.nunique())\n",
    "print(ratings_df.movieId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users is: 610\n",
      "Number of unique items/ratings is: 9724\n",
      "Number of ratings 100836\n",
      "Matrix size: 5931640\n",
      "Percent of matrix that is filled: 1.6999683055613624 %\n"
     ]
    }
   ],
   "source": [
    "n_users = ratings_df.userId.nunique()\n",
    "n_movies = ratings_df.movieId.nunique()\n",
    "\n",
    "print(\"Number of unique users is:\", n_users)\n",
    "print(\"Number of unique items/ratings is:\", n_movies)\n",
    "print(\"Number of ratings\", len(ratings_df))\n",
    "print(\"Matrix size:\", n_users*n_movies)\n",
    "print(\"Percent of matrix that is filled:\", len(ratings_df) / (n_users*n_movies) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#import mathplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, metrics, model_selection\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "        \n",
    "    # len(movie_dataset)\n",
    "    def __len__(self): # Number of Users\n",
    "        return len(self.users)\n",
    "\n",
    "    # movie_dataset[1]\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        users = self.users[idx]\n",
    "        movies = self.movies[idx]\n",
    "        ratings = self.ratings[idx]\n",
    "\n",
    "        return {\n",
    "            \"users\" : torch.tensor(users, dtype=torch.long),\n",
    "            \"movies\" : torch.tensor(movies, dtype=torch.long),\n",
    "            \"ratings\" : torch.tensor(ratings, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSysModel(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_movies, embedding_size=256, hidden_dim=256, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        #create embeddings\n",
    "        self.user_embed = torch.nn.Embedding(num_embeddings=n_users, embedding_dim=embedding_size)\n",
    "        self.movie_embed = torch.nn.Embedding(num_embeddings=n_movies, embedding_dim=embedding_size)\n",
    "\n",
    "\n",
    "        # hidden layers\n",
    "        self.fc1 = torch.nn.Linear(2 * embedding_size, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, users, movies, ratings=None):\n",
    "        user_embeds = self.user_embed(users)\n",
    "        movie_embeds = self.movie_embed(movies)\n",
    "        \n",
    "        output = torch.cat([user_embeds, movie_embeds], dim=1)\n",
    "\n",
    "        x = self.relu(self.fc1(output))\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "ratings_df.userId = lbl_user.fit_transform(ratings_df.userId.values)\n",
    "ratings_df.movieId = lbl_movie.fit_transform(ratings_df.movieId.values)\n",
    "\n",
    "df_train, df_valid = model_selection.train_test_split(\n",
    "    ratings_df, test_size=0.1, random_state=3, stratify=ratings_df.rating.values\n",
    ")\n",
    "\n",
    "train_dataset = MovieDataset(\n",
    "    users = df_train.userId.values,\n",
    "    movies = df_train.movieId.values,\n",
    "    ratings = df_train.rating.values\n",
    ")\n",
    "\n",
    "valid_dataset = MovieDataset(\n",
    "    users = df_valid.userId.values,\n",
    "    movies = df_valid.movieId.values,\n",
    "    ratings = df_valid.rating.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(lbl_user.classes_)#num of unique users\n",
    "n_movies = len(lbl_movie.classes_)#unique movies\n",
    "\n",
    "recommendation_model = RecSysModel(n_users, n_movies, embedding_size=64, hidden_dim=128, dropout_rate=0.1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(recommendation_model.parameters()) #gradient descent aka adjust to yield smallest error\n",
    "sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on size: 90752\n",
      "epoch 0 loss at step 800 is 2.6386972951889036\n",
      "epoch 0 loss at step 1600 is 1.3006292653083802\n",
      "epoch 0 loss at step 2400 is 0.6132201683521271\n",
      "epoch 0 loss at step 3200 is 0.4252203130722046\n",
      "epoch 0 loss at step 4000 is 0.3355283379554749\n",
      "epoch 0 loss at step 4800 is 0.334689319729805\n",
      "epoch 0 loss at step 5600 is 0.3007928156852722\n",
      "epoch 0 loss at step 6400 is 0.3045295637845993\n",
      "epoch 0 loss at step 7200 is 0.2920352590084076\n",
      "epoch 0 loss at step 8000 is 0.29119313657283785\n",
      "epoch 0 loss at step 8800 is 0.3085030776262283\n",
      "epoch 0 loss at step 9600 is 0.29866264522075653\n",
      "epoch 0 loss at step 10400 is 0.2712466084957123\n",
      "epoch 0 loss at step 11200 is 0.261068257689476\n",
      "epoch 0 loss at step 12000 is 0.27726986587047575\n",
      "epoch 0 loss at step 12800 is 0.29164719879627227\n",
      "epoch 0 loss at step 13600 is 0.29744533717632293\n",
      "epoch 0 loss at step 14400 is 0.26924890518188477\n",
      "epoch 0 loss at step 15200 is 0.26626304030418396\n",
      "epoch 0 loss at step 16000 is 0.2672853118181229\n",
      "epoch 0 loss at step 16800 is 0.250841521024704\n",
      "epoch 0 loss at step 17600 is 0.2569271832704544\n",
      "epoch 0 loss at step 18400 is 0.25950020134449003\n",
      "epoch 0 loss at step 19200 is 0.25470940947532655\n",
      "epoch 0 loss at step 20000 is 0.26156419694423677\n",
      "epoch 0 loss at step 20800 is 0.25275027871131894\n",
      "epoch 0 loss at step 21600 is 0.26696021676063536\n",
      "epoch 0 loss at step 22400 is 0.2587841945886612\n",
      "epoch 0 loss at step 23200 is 0.2388752979040146\n",
      "epoch 0 loss at step 24000 is 0.2665933507680893\n",
      "epoch 0 loss at step 24800 is 0.2661159908771515\n",
      "epoch 0 loss at step 25600 is 0.25669785976409915\n",
      "epoch 0 loss at step 26400 is 0.25435563445091247\n",
      "epoch 0 loss at step 27200 is 0.2491747498512268\n",
      "epoch 0 loss at step 28000 is 0.24499074041843413\n",
      "epoch 0 loss at step 28800 is 0.2658706986904144\n",
      "epoch 0 loss at step 29600 is 0.25584068059921267\n",
      "epoch 0 loss at step 30400 is 0.25502992153167725\n",
      "epoch 0 loss at step 31200 is 0.24974222481250763\n",
      "epoch 0 loss at step 32000 is 0.24395549148321152\n",
      "epoch 0 loss at step 32800 is 0.22509479522705078\n",
      "epoch 0 loss at step 33600 is 0.25705317318439486\n",
      "epoch 0 loss at step 34400 is 0.2437974452972412\n",
      "epoch 0 loss at step 35200 is 0.24561248779296874\n",
      "epoch 0 loss at step 36000 is 0.22613254964351653\n",
      "epoch 0 loss at step 36800 is 0.23421044558286666\n",
      "epoch 0 loss at step 37600 is 0.23693739831447602\n",
      "epoch 0 loss at step 38400 is 0.23727497100830078\n",
      "epoch 0 loss at step 39200 is 0.22304442524909973\n",
      "epoch 0 loss at step 40000 is 0.2367941176891327\n",
      "epoch 0 loss at step 40800 is 0.2451318895816803\n",
      "epoch 0 loss at step 41600 is 0.2360081022977829\n",
      "epoch 0 loss at step 42400 is 0.21904873877763748\n",
      "epoch 0 loss at step 43200 is 0.2744928604364395\n",
      "epoch 0 loss at step 44000 is 0.23474738866090775\n",
      "epoch 0 loss at step 44800 is 0.22981931924819946\n",
      "epoch 0 loss at step 45600 is 0.22465797781944274\n",
      "epoch 0 loss at step 46400 is 0.25427725732326506\n",
      "epoch 0 loss at step 47200 is 0.24078026294708252\n",
      "epoch 0 loss at step 48000 is 0.23373798966407777\n",
      "epoch 0 loss at step 48800 is 0.24464558243751525\n",
      "epoch 0 loss at step 49600 is 0.2512212646007538\n",
      "epoch 0 loss at step 50400 is 0.2614798337221146\n",
      "epoch 0 loss at step 51200 is 0.24578689873218537\n",
      "epoch 0 loss at step 52000 is 0.2381540995836258\n",
      "epoch 0 loss at step 52800 is 0.228658983707428\n",
      "epoch 0 loss at step 53600 is 0.227156121134758\n",
      "epoch 0 loss at step 54400 is 0.24482933342456817\n",
      "epoch 0 loss at step 55200 is 0.2298370271921158\n",
      "epoch 0 loss at step 56000 is 0.2341996717453003\n",
      "epoch 0 loss at step 56800 is 0.21710081338882448\n",
      "epoch 0 loss at step 57600 is 0.24221233248710633\n",
      "epoch 0 loss at step 58400 is 0.24102052092552184\n",
      "epoch 0 loss at step 59200 is 0.2432679569721222\n",
      "epoch 0 loss at step 60000 is 0.22760623574256897\n",
      "epoch 0 loss at step 60800 is 0.23613663107156754\n",
      "epoch 0 loss at step 61600 is 0.2374131613969803\n",
      "epoch 0 loss at step 62400 is 0.24207771360874175\n",
      "epoch 0 loss at step 63200 is 0.22016797184944153\n",
      "epoch 0 loss at step 64000 is 0.23189651995897292\n",
      "epoch 0 loss at step 64800 is 0.21898802399635314\n",
      "epoch 0 loss at step 65600 is 0.22823352813720704\n",
      "epoch 0 loss at step 66400 is 0.23912797391414642\n",
      "epoch 0 loss at step 67200 is 0.22735184967517852\n",
      "epoch 0 loss at step 68000 is 0.24697338461875915\n",
      "epoch 0 loss at step 68800 is 0.2270983350276947\n",
      "epoch 0 loss at step 69600 is 0.23358430624008178\n",
      "epoch 0 loss at step 70400 is 0.2619351375102997\n",
      "epoch 0 loss at step 71200 is 0.23176298469305037\n",
      "epoch 0 loss at step 72000 is 0.21000801742076874\n",
      "epoch 0 loss at step 72800 is 0.23088087499141693\n",
      "epoch 0 loss at step 73600 is 0.24109463930130004\n",
      "epoch 0 loss at step 74400 is 0.22399416863918303\n",
      "epoch 0 loss at step 75200 is 0.2319795620441437\n",
      "epoch 0 loss at step 76000 is 0.2481236505508423\n",
      "epoch 0 loss at step 76800 is 0.22804949581623077\n",
      "epoch 0 loss at step 77600 is 0.22905675530433656\n",
      "epoch 0 loss at step 78400 is 0.22604126930236818\n",
      "epoch 0 loss at step 79200 is 0.23267237961292267\n",
      "epoch 0 loss at step 80000 is 0.21412901431322098\n",
      "epoch 0 loss at step 80800 is 0.21792883276939393\n",
      "epoch 0 loss at step 81600 is 0.2158834880590439\n",
      "epoch 0 loss at step 82400 is 0.23138717651367188\n",
      "epoch 0 loss at step 83200 is 0.21871213585138322\n",
      "epoch 0 loss at step 84000 is 0.2487134939432144\n",
      "epoch 0 loss at step 84800 is 0.235906620323658\n",
      "epoch 0 loss at step 85600 is 0.2447504585981369\n",
      "epoch 0 loss at step 86400 is 0.2245770537853241\n",
      "epoch 0 loss at step 87200 is 0.22916442424058914\n",
      "epoch 0 loss at step 88000 is 0.2349051493406296\n",
      "epoch 0 loss at step 88800 is 0.2355109041929245\n",
      "epoch 0 loss at step 89600 is 0.23018735587596895\n",
      "epoch 0 loss at step 90400 is 0.23027461290359497\n",
      "epoch 0 loss at step 90752 is 0.10982057422399522\n",
      "epoch 1 loss at step 800 is 0.21037020146846772\n",
      "epoch 1 loss at step 1600 is 0.19802071541547775\n",
      "epoch 1 loss at step 2400 is 0.21998712182044983\n",
      "epoch 1 loss at step 3200 is 0.2152981334924698\n",
      "epoch 1 loss at step 4000 is 0.20942607372999192\n",
      "epoch 1 loss at step 4800 is 0.19052620708942414\n",
      "epoch 1 loss at step 5600 is 0.2073264342546463\n",
      "epoch 1 loss at step 6400 is 0.20695786744356157\n",
      "epoch 1 loss at step 7200 is 0.2128007709980011\n",
      "epoch 1 loss at step 8000 is 0.21854963511228562\n",
      "epoch 1 loss at step 8800 is 0.21071053236722947\n",
      "epoch 1 loss at step 9600 is 0.2128353276848793\n",
      "epoch 1 loss at step 10400 is 0.21808238804340363\n",
      "epoch 1 loss at step 11200 is 0.20820999026298523\n",
      "epoch 1 loss at step 12000 is 0.21718504786491394\n",
      "epoch 1 loss at step 12800 is 0.20131680101156235\n",
      "epoch 1 loss at step 13600 is 0.21527509331703187\n",
      "epoch 1 loss at step 14400 is 0.22847845077514647\n",
      "epoch 1 loss at step 15200 is 0.21028546303510665\n",
      "epoch 1 loss at step 16000 is 0.21717191159725188\n",
      "epoch 1 loss at step 16800 is 0.22014659643173218\n",
      "epoch 1 loss at step 17600 is 0.19793896108865738\n",
      "epoch 1 loss at step 18400 is 0.201729496717453\n",
      "epoch 1 loss at step 19200 is 0.21553604006767274\n",
      "epoch 1 loss at step 20000 is 0.22855544060468674\n",
      "epoch 1 loss at step 20800 is 0.2138619104027748\n",
      "epoch 1 loss at step 21600 is 0.21032890021800996\n",
      "epoch 1 loss at step 22400 is 0.21778169751167298\n",
      "epoch 1 loss at step 23200 is 0.21351563602685927\n",
      "epoch 1 loss at step 24000 is 0.20168229103088378\n",
      "epoch 1 loss at step 24800 is 0.22017692148685455\n",
      "epoch 1 loss at step 25600 is 0.21960569471120833\n",
      "epoch 1 loss at step 26400 is 0.24206591188907622\n",
      "epoch 1 loss at step 27200 is 0.2183959323167801\n",
      "epoch 1 loss at step 28000 is 0.19853153169155122\n",
      "epoch 1 loss at step 28800 is 0.2225945433974266\n",
      "epoch 1 loss at step 29600 is 0.2330339515209198\n",
      "epoch 1 loss at step 30400 is 0.2305365478992462\n",
      "epoch 1 loss at step 31200 is 0.2094028651714325\n",
      "epoch 1 loss at step 32000 is 0.18951314866542815\n",
      "epoch 1 loss at step 32800 is 0.19709088027477265\n",
      "epoch 1 loss at step 33600 is 0.21407554388046265\n",
      "epoch 1 loss at step 34400 is 0.2105792135000229\n",
      "epoch 1 loss at step 35200 is 0.20115021109580994\n",
      "epoch 1 loss at step 36000 is 0.20813024580478667\n",
      "epoch 1 loss at step 36800 is 0.2186906525492668\n",
      "epoch 1 loss at step 37600 is 0.2103166651725769\n",
      "epoch 1 loss at step 38400 is 0.2198294848203659\n",
      "epoch 1 loss at step 39200 is 0.19740599751472473\n",
      "epoch 1 loss at step 40000 is 0.22121159195899964\n",
      "epoch 1 loss at step 40800 is 0.20303792893886566\n",
      "epoch 1 loss at step 41600 is 0.19103063225746156\n",
      "epoch 1 loss at step 42400 is 0.1865239554643631\n",
      "epoch 1 loss at step 43200 is 0.20803883880376817\n",
      "epoch 1 loss at step 44000 is 0.20355416476726532\n",
      "epoch 1 loss at step 44800 is 0.18562850534915923\n",
      "epoch 1 loss at step 45600 is 0.18816727459430693\n",
      "epoch 1 loss at step 46400 is 0.20293822526931762\n",
      "epoch 1 loss at step 47200 is 0.2087391921877861\n",
      "epoch 1 loss at step 48000 is 0.1846040403842926\n",
      "epoch 1 loss at step 48800 is 0.20056876868009568\n",
      "epoch 1 loss at step 49600 is 0.20040510088205338\n",
      "epoch 1 loss at step 50400 is 0.199602372944355\n",
      "epoch 1 loss at step 51200 is 0.20631569981575013\n",
      "epoch 1 loss at step 52000 is 0.23823511958122254\n",
      "epoch 1 loss at step 52800 is 0.1942659205198288\n",
      "epoch 1 loss at step 53600 is 0.22163751661777498\n",
      "epoch 1 loss at step 54400 is 0.20023753196001054\n",
      "epoch 1 loss at step 55200 is 0.21856212437152864\n",
      "epoch 1 loss at step 56000 is 0.2223304584622383\n",
      "epoch 1 loss at step 56800 is 0.19414481461048128\n",
      "epoch 1 loss at step 57600 is 0.21848392009735107\n",
      "epoch 1 loss at step 58400 is 0.1992749536037445\n",
      "epoch 1 loss at step 59200 is 0.2236107122898102\n",
      "epoch 1 loss at step 60000 is 0.20399393260478973\n",
      "epoch 1 loss at step 60800 is 0.20522776991128922\n",
      "epoch 1 loss at step 61600 is 0.19094096451997758\n",
      "epoch 1 loss at step 62400 is 0.21027866125106812\n",
      "epoch 1 loss at step 63200 is 0.19771486431360244\n",
      "epoch 1 loss at step 64000 is 0.19961510419845582\n",
      "epoch 1 loss at step 64800 is 0.22460766196250914\n",
      "epoch 1 loss at step 65600 is 0.2048048508167267\n",
      "epoch 1 loss at step 66400 is 0.20562942266464235\n",
      "epoch 1 loss at step 67200 is 0.19126992493867875\n",
      "epoch 1 loss at step 68000 is 0.20303997695446013\n",
      "epoch 1 loss at step 68800 is 0.22637867152690888\n",
      "epoch 1 loss at step 69600 is 0.19955108761787416\n",
      "epoch 1 loss at step 70400 is 0.22131209790706635\n",
      "epoch 1 loss at step 71200 is 0.2202228319644928\n",
      "epoch 1 loss at step 72000 is 0.1897649747133255\n",
      "epoch 1 loss at step 72800 is 0.202227982878685\n",
      "epoch 1 loss at step 73600 is 0.23167864233255386\n",
      "epoch 1 loss at step 74400 is 0.18897299021482467\n",
      "epoch 1 loss at step 75200 is 0.2241384792327881\n",
      "epoch 1 loss at step 76000 is 0.20676478922367095\n",
      "epoch 1 loss at step 76800 is 0.19550773173570632\n",
      "epoch 1 loss at step 77600 is 0.19552262097597123\n",
      "epoch 1 loss at step 78400 is 0.19403279721736907\n",
      "epoch 1 loss at step 79200 is 0.1927851629257202\n",
      "epoch 1 loss at step 80000 is 0.21078939706087113\n",
      "epoch 1 loss at step 80800 is 0.21354134917259215\n",
      "epoch 1 loss at step 81600 is 0.2160337448120117\n",
      "epoch 1 loss at step 82400 is 0.22483783930540086\n",
      "epoch 1 loss at step 83200 is 0.21243521869182586\n",
      "epoch 1 loss at step 84000 is 0.21083665698766707\n",
      "epoch 1 loss at step 84800 is 0.1953373694419861\n",
      "epoch 1 loss at step 85600 is 0.22043450713157653\n",
      "epoch 1 loss at step 86400 is 0.22399434506893157\n",
      "epoch 1 loss at step 87200 is 0.19778529644012452\n",
      "epoch 1 loss at step 88000 is 0.19814079940319063\n",
      "epoch 1 loss at step 88800 is 0.21117767930030823\n",
      "epoch 1 loss at step 89600 is 0.22973439633846282\n",
      "epoch 1 loss at step 90400 is 0.19773883253335953\n",
      "epoch 1 loss at step 90752 is 0.0961200699210167\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "def train():\n",
    "    epochs = 2\n",
    "    total_loss = 0\n",
    "    log_step = 100\n",
    "    \n",
    "    print(f'Training on size: {len(train_dataset)}')\n",
    "    recommendation_model.train()\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        step_count = 0\n",
    "        for i, train_data in enumerate(train_loader):\n",
    "            users = train_data[\"users\"].to(device)\n",
    "            movies = train_data[\"movies\"].to(device)\n",
    "    \n",
    "            output = recommendation_model(users, movies)\n",
    "            output = output.squeeze()\n",
    "            \n",
    "            ratings = train_data[\"ratings\"].to(torch.float32).to(device)\n",
    "    \n",
    "            \n",
    "    \n",
    "            loss = loss_fn(output, ratings)\n",
    "            total_loss += loss.sum().item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            step_count += len(train_data[\"users\"])\n",
    "    \n",
    "            if (step_count % log_step == 0 or i == len(train_loader) - 1):\n",
    "                avg_loss = (total_loss / log_step)\n",
    "                print(f\"epoch {epoch_i} loss at step {step_count} is {avg_loss}\")\n",
    "                losses.append(avg_loss)\n",
    "                total_loss = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9080\n"
     ]
    }
   ],
   "source": [
    "  # Root Mean Squared Error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "recommendation_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, valid_data in enumerate(valid_loader):\n",
    "        model_output = recommendation_model(valid_data['users'].to(device), valid_data['movies'].to(device))\n",
    "\n",
    "        ratings = valid_data['ratings'].to(device)\n",
    "        y_true.extend(ratings.cpu().numpy()) \n",
    "        y_pred.extend(model_output.cpu().numpy())\n",
    "\n",
    "\n",
    "# actually calc RMSE\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision @ 50: 0.8899\n",
      "recall @ 50: 0.8818\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calculate_precision_recall(user_ratings, k, threshold):\n",
    "    user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "    n_rel = sum(true_r >= threshold for _, true_r in user_ratings)\n",
    "    n_rec_k = sum(est >= threshold for est, _ in user_ratings[:k])\n",
    "    n_rel_and_rec_k = sum(\n",
    "        (true_r >= threshold) and (est >= threshold) for est, true_r in user_ratings[:k]\n",
    "    )\n",
    "\n",
    "    precision = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "    recall = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "user_ratings_comparison = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for valid_data in valid_loader:\n",
    "        users = valid_data[\"users\"].to(device)\n",
    "        movies = valid_data[\"movies\"].to(device)\n",
    "        ratings = valid_data[\"ratings\"].to(device)\n",
    "        output = recommendation_model(users, movies)\n",
    "\n",
    "        for user, pred, true in zip(users, output, ratings):\n",
    "            user_ratings_comparison[user.item()].append((pred[0].item(), true.item()))\n",
    "\n",
    "user_precisions = dict()\n",
    "user_based_recalls = dict()\n",
    "\n",
    "k = 50\n",
    "threshold = 3\n",
    "\n",
    "for user_id, user_ratings in user_ratings_comparison.items():\n",
    "    precision, recall = calculate_precision_recall(user_ratings, k, threshold)\n",
    "    user_precisions[user_id] = precision\n",
    "    user_based_recalls[user_id] = recall\n",
    "\n",
    "\n",
    "    average_precision = sum(prec for prec in user_precisions.values()) / len(\n",
    "    user_precisions\n",
    ")\n",
    "average_recall = sum(rec for rec in user_based_recalls.values()) / len(\n",
    "    user_based_recalls\n",
    ")\n",
    "\n",
    "print(f\"precision @ {k}: {average_precision:.4f}\")\n",
    "print(f\"recall @ {k}: {average_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 1: [4957  260  741 4154 5685]\n",
      "Sudden Impact (1983)\n",
      "Star Wars: Episode IV - A New Hope (1977)\n",
      "Ghost in the Shell (Kôkaku kidôtai) (1995)\n",
      "Recess: School's Out (2001)\n",
      "Real Women Have Curves (2002)\n",
      "Recommendations for user 5: [ 187 4154  741 1178 5685]\n",
      "Party Girl (1995)\n",
      "Recess: School's Out (2001)\n",
      "Ghost in the Shell (Kôkaku kidôtai) (1995)\n",
      "Paths of Glory (1957)\n",
      "Real Women Have Curves (2002)\n"
     ]
    }
   ],
   "source": [
    "def top_recommendations(user_id, all_movies, k=5, batch_size=100):\n",
    "    recommendation_model.eval()\n",
    "\n",
    "\n",
    "    \n",
    "    watched_movies = set(ratings_df[ratings_df['userId'] == user_id]['movieId'].tolist())\n",
    "    unwatched_movies = [m for m in all_movies if m not in watched_movies]\n",
    "    # fill unwatched movies\n",
    "    # for m in all_movies:\n",
    "    #     if m not in watched_movies:\n",
    "    #         unwatched_movies.append(m)\n",
    "\n",
    "    prediction = []\n",
    "    top_k_recommendations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(unwatched_movies), batch_size):\n",
    "            batched_unwatched = unwatched_movies[i:i+batch_size]\n",
    "            movie_tensor = torch.tensor(batched_unwatched).to(device)\n",
    "            user_tensor = torch.tensor([user_id] * len(batched_unwatched)).to(device)\n",
    "            prediction_model = recommendation_model(user_tensor, movie_tensor).view(-1).tolist()\n",
    "            prediction.extend(zip(batched_unwatched, prediction_model))\n",
    "\n",
    "    prediction.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for (m_id, _) in prediction[:k]:\n",
    "        top_k_recommendations.append(m_id)\n",
    "\n",
    "    # Convert this encoded movieId's back to their original ids\n",
    "    top_k_recommendations = lbl_movie.inverse_transform(top_k_recommendations)\n",
    "    \n",
    "    return top_k_recommendations\n",
    "\n",
    "# ---------------\n",
    "\n",
    "all_movies = ratings_df['movieId'].unique().tolist()\n",
    "user_id = 1\n",
    "\n",
    "recommendations = top_recommendations(user_id, all_movies, k=5)\n",
    "print(f\"Recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "for i in recommendations:\n",
    "    print(movies_dict[i])\n",
    "\n",
    "user_id = 5\n",
    "recommendations = top_recommendations(user_id, all_movies, k=5)\n",
    "print(f\"Recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "for i in recommendations:\n",
    "    print(movies_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
