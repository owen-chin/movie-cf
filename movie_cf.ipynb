{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "movies_df = pd.read_csv(\"data/ml-latest-small/movies.csv\")\n",
    "ratings_df = pd.read_csv(\"data/ml-latest-small/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_dict = movies_df.set_index('movieId')[\"title\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>193581</td>\n",
       "      <td>Black Butler: Book of the Atlantic (2017)</td>\n",
       "      <td>Action|Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>193583</td>\n",
       "      <td>No Game No Life: Zero (2017)</td>\n",
       "      <td>Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>193585</td>\n",
       "      <td>Flint (2017)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>193587</td>\n",
       "      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n",
       "      <td>Action|Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>193609</td>\n",
       "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9742 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                      title  \\\n",
       "0           1                           Toy Story (1995)   \n",
       "1           2                             Jumanji (1995)   \n",
       "2           3                    Grumpier Old Men (1995)   \n",
       "3           4                   Waiting to Exhale (1995)   \n",
       "4           5         Father of the Bride Part II (1995)   \n",
       "...       ...                                        ...   \n",
       "9737   193581  Black Butler: Book of the Atlantic (2017)   \n",
       "9738   193583               No Game No Life: Zero (2017)   \n",
       "9739   193585                               Flint (2017)   \n",
       "9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n",
       "9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n",
       "\n",
       "                                           genres  \n",
       "0     Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                      Adventure|Children|Fantasy  \n",
       "2                                  Comedy|Romance  \n",
       "3                            Comedy|Drama|Romance  \n",
       "4                                          Comedy  \n",
       "...                                           ...  \n",
       "9737              Action|Animation|Comedy|Fantasy  \n",
       "9738                     Animation|Comedy|Fantasy  \n",
       "9739                                        Drama  \n",
       "9740                             Action|Animation  \n",
       "9741                                       Comedy  \n",
       "\n",
       "[9742 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "4.0    26818\n",
       "3.0    20047\n",
       "5.0    13211\n",
       "3.5    13136\n",
       "4.5     8551\n",
       "2.0     7551\n",
       "2.5     5550\n",
       "1.0     2811\n",
       "1.5     1791\n",
       "0.5     1370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users is: 610\n",
      "Number of unique items/ratings is: 9724\n",
      "Number of ratings 100836\n",
      "Matrix size: 5931640\n",
      "Percent of matrix that is filled: 1.6999683055613624 %\n"
     ]
    }
   ],
   "source": [
    "n_users = ratings_df.userId.nunique()\n",
    "n_movies = ratings_df.movieId.nunique()\n",
    "\n",
    "print(\"Number of unique users is:\", n_users)\n",
    "print(\"Number of unique items/ratings is:\", n_movies)\n",
    "print(\"Number of ratings\", len(ratings_df))\n",
    "print(\"Matrix size:\", n_users*n_movies)\n",
    "print(\"Percent of matrix that is filled:\", len(ratings_df) / (n_users*n_movies) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#import mathplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, metrics, model_selection\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "        \n",
    "    # len(movie_dataset)\n",
    "    def __len__(self): # Number of Users\n",
    "        return len(self.users)\n",
    "\n",
    "    # movie_dataset[1]\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        users = self.users[idx]\n",
    "        movies = self.movies[idx]\n",
    "        ratings = self.ratings[idx]\n",
    "\n",
    "        return {\n",
    "            \"users\" : torch.tensor(users, dtype=torch.long),\n",
    "            \"movies\" : torch.tensor(movies, dtype=torch.long),\n",
    "            \"ratings\" : torch.tensor(ratings, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSysModel(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_movies, embedding_size=256, hidden_dim=256, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        #create embeddings\n",
    "        self.user_embed = torch.nn.Embedding(num_embeddings=n_users, embedding_dim=embedding_size)\n",
    "        self.movie_embed = torch.nn.Embedding(num_embeddings=n_movies, embedding_dim=embedding_size)\n",
    "\n",
    "\n",
    "        # hidden layers\n",
    "        self.fc1 = torch.nn.Linear(2 * embedding_size, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, users, movies, ratings=None):\n",
    "        user_embeds = self.user_embed(users)\n",
    "        movie_embeds = self.movie_embed(movies)\n",
    "        \n",
    "        output = torch.cat([user_embeds, movie_embeds], dim=1)\n",
    "\n",
    "        x = self.relu(self.fc1(output))\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "ratings_df.userId = lbl_user.fit_transform(ratings_df.userId.values)\n",
    "ratings_df.movieId = lbl_movie.fit_transform(ratings_df.movieId.values)\n",
    "\n",
    "df_train, df_valid = model_selection.train_test_split(\n",
    "    ratings_df, test_size=0.1, random_state=3, stratify=ratings_df.rating.values\n",
    ")\n",
    "\n",
    "train_dataset = MovieDataset(\n",
    "    users = df_train.userId.values,\n",
    "    movies = df_train.movieId.values,\n",
    "    ratings = df_train.rating.values\n",
    ")\n",
    "\n",
    "valid_dataset = MovieDataset(\n",
    "    users = df_valid.userId.values,\n",
    "    movies = df_valid.movieId.values,\n",
    "    ratings = df_valid.rating.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(lbl_user.classes_)#num of unique users\n",
    "n_movies = len(lbl_movie.classes_)#unique movies\n",
    "\n",
    "recommendation_model = RecSysModel(n_users, n_movies, embedding_size=64, hidden_dim=128, dropout_rate=0.1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(recommendation_model.parameters()) #gradient descent aka adjust to yield smallest error\n",
    "sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on size: 90752\n",
      "epoch 0 loss at step 800 is 2.640936026573181\n",
      "epoch 0 loss at step 1600 is 1.4767269611358642\n",
      "epoch 0 loss at step 2400 is 0.677784765958786\n",
      "epoch 0 loss at step 3200 is 0.45631691098213195\n",
      "epoch 0 loss at step 4000 is 0.38076083838939667\n",
      "epoch 0 loss at step 4800 is 0.3412595194578171\n",
      "epoch 0 loss at step 5600 is 0.31564661502838137\n",
      "epoch 0 loss at step 6400 is 0.2958056223392487\n",
      "epoch 0 loss at step 7200 is 0.2932812172174454\n",
      "epoch 0 loss at step 8000 is 0.2988382041454315\n",
      "epoch 0 loss at step 8800 is 0.27746612191200254\n",
      "epoch 0 loss at step 9600 is 0.28879789233207703\n",
      "epoch 0 loss at step 10400 is 0.27675289392471314\n",
      "epoch 0 loss at step 11200 is 0.24825926899909972\n",
      "epoch 0 loss at step 12000 is 0.28352441132068634\n",
      "epoch 0 loss at step 12800 is 0.2893728268146515\n",
      "epoch 0 loss at step 13600 is 0.3013695549964905\n",
      "epoch 0 loss at step 14400 is 0.2801610678434372\n",
      "epoch 0 loss at step 15200 is 0.27290764212608337\n",
      "epoch 0 loss at step 16000 is 0.2565966123342514\n",
      "epoch 0 loss at step 16800 is 0.26217022895812986\n",
      "epoch 0 loss at step 17600 is 0.2425785505771637\n",
      "epoch 0 loss at step 18400 is 0.26125203490257265\n",
      "epoch 0 loss at step 19200 is 0.25226504445075987\n",
      "epoch 0 loss at step 20000 is 0.28761527955532074\n",
      "epoch 0 loss at step 20800 is 0.23723295271396638\n",
      "epoch 0 loss at step 21600 is 0.2670647579431534\n",
      "epoch 0 loss at step 22400 is 0.2516561675071716\n",
      "epoch 0 loss at step 23200 is 0.2625046491622925\n",
      "epoch 0 loss at step 24000 is 0.24977228462696074\n",
      "epoch 0 loss at step 24800 is 0.24740170776844025\n",
      "epoch 0 loss at step 25600 is 0.24580566108226776\n",
      "epoch 0 loss at step 26400 is 0.2666474390029907\n",
      "epoch 0 loss at step 27200 is 0.24977095186710357\n",
      "epoch 0 loss at step 28000 is 0.2726417595148087\n",
      "epoch 0 loss at step 28800 is 0.2698409593105316\n",
      "epoch 0 loss at step 29600 is 0.24318015873432158\n",
      "epoch 0 loss at step 30400 is 0.2664192724227905\n",
      "epoch 0 loss at step 31200 is 0.2640239870548248\n",
      "epoch 0 loss at step 32000 is 0.27806113064289095\n",
      "epoch 0 loss at step 32800 is 0.24265369296073913\n",
      "epoch 0 loss at step 33600 is 0.26355570793151856\n",
      "epoch 0 loss at step 34400 is 0.24149783194065094\n",
      "epoch 0 loss at step 35200 is 0.24706223785877227\n",
      "epoch 0 loss at step 36000 is 0.26416167795658113\n",
      "epoch 0 loss at step 36800 is 0.22332908362150192\n",
      "epoch 0 loss at step 37600 is 0.2525947952270508\n",
      "epoch 0 loss at step 38400 is 0.22771947860717773\n",
      "epoch 0 loss at step 39200 is 0.250270157456398\n",
      "epoch 0 loss at step 40000 is 0.25072636514902114\n",
      "epoch 0 loss at step 40800 is 0.23837790369987488\n",
      "epoch 0 loss at step 41600 is 0.23250734210014343\n",
      "epoch 0 loss at step 42400 is 0.22320154935121536\n",
      "epoch 0 loss at step 43200 is 0.24681659936904907\n",
      "epoch 0 loss at step 44000 is 0.23145358979701997\n",
      "epoch 0 loss at step 44800 is 0.24410151183605194\n",
      "epoch 0 loss at step 45600 is 0.23096052855253218\n",
      "epoch 0 loss at step 46400 is 0.25244810968637466\n",
      "epoch 0 loss at step 47200 is 0.25116489112377166\n",
      "epoch 0 loss at step 48000 is 0.24402811110019684\n",
      "epoch 0 loss at step 48800 is 0.2173967933654785\n",
      "epoch 0 loss at step 49600 is 0.2116958913207054\n",
      "epoch 0 loss at step 50400 is 0.23100872635841369\n",
      "epoch 0 loss at step 51200 is 0.2548538374900818\n",
      "epoch 0 loss at step 52000 is 0.2558442038297653\n",
      "epoch 0 loss at step 52800 is 0.19718997776508332\n",
      "epoch 0 loss at step 53600 is 0.2361494094133377\n",
      "epoch 0 loss at step 54400 is 0.22231930315494539\n",
      "epoch 0 loss at step 55200 is 0.2584236371517181\n",
      "epoch 0 loss at step 56000 is 0.23253351897001268\n",
      "epoch 0 loss at step 56800 is 0.2295338386297226\n",
      "epoch 0 loss at step 57600 is 0.24869508683681488\n",
      "epoch 0 loss at step 58400 is 0.2588645380735397\n",
      "epoch 0 loss at step 59200 is 0.2433873587846756\n",
      "epoch 0 loss at step 60000 is 0.22858449161052705\n",
      "epoch 0 loss at step 60800 is 0.22458856344223022\n",
      "epoch 0 loss at step 61600 is 0.26100348591804506\n",
      "epoch 0 loss at step 62400 is 0.2256127279996872\n",
      "epoch 0 loss at step 63200 is 0.2368676096200943\n",
      "epoch 0 loss at step 64000 is 0.24181626498699188\n",
      "epoch 0 loss at step 64800 is 0.22982809603214263\n",
      "epoch 0 loss at step 65600 is 0.23967286050319672\n",
      "epoch 0 loss at step 66400 is 0.22900720953941345\n",
      "epoch 0 loss at step 67200 is 0.24037918984889983\n",
      "epoch 0 loss at step 68000 is 0.23014912486076355\n",
      "epoch 0 loss at step 68800 is 0.23036259889602662\n",
      "epoch 0 loss at step 69600 is 0.22170049101114273\n",
      "epoch 0 loss at step 70400 is 0.2433227163553238\n",
      "epoch 0 loss at step 71200 is 0.23399595499038697\n",
      "epoch 0 loss at step 72000 is 0.2353070342540741\n",
      "epoch 0 loss at step 72800 is 0.22717639982700347\n",
      "epoch 0 loss at step 73600 is 0.2357184398174286\n",
      "epoch 0 loss at step 74400 is 0.2166447803378105\n",
      "epoch 0 loss at step 75200 is 0.20542282938957215\n",
      "epoch 0 loss at step 76000 is 0.2468295732140541\n",
      "epoch 0 loss at step 76800 is 0.22926565170288085\n",
      "epoch 0 loss at step 77600 is 0.22557660460472106\n",
      "epoch 0 loss at step 78400 is 0.22234342217445374\n",
      "epoch 0 loss at step 79200 is 0.23148539483547212\n",
      "epoch 0 loss at step 80000 is 0.23867262184619903\n",
      "epoch 0 loss at step 80800 is 0.2354290008544922\n",
      "epoch 0 loss at step 81600 is 0.21250294625759125\n",
      "epoch 0 loss at step 82400 is 0.2336101198196411\n",
      "epoch 0 loss at step 83200 is 0.21927180051803588\n",
      "epoch 0 loss at step 84000 is 0.22514485716819763\n",
      "epoch 0 loss at step 84800 is 0.2172246351838112\n",
      "epoch 0 loss at step 85600 is 0.24450633347034453\n",
      "epoch 0 loss at step 86400 is 0.23628196895122527\n",
      "epoch 0 loss at step 87200 is 0.21343497067689896\n",
      "epoch 0 loss at step 88000 is 0.22168418109416962\n",
      "epoch 0 loss at step 88800 is 0.24292528092861176\n",
      "epoch 0 loss at step 89600 is 0.21845507323741914\n",
      "epoch 0 loss at step 90400 is 0.22622850000858308\n",
      "epoch 0 loss at step 90752 is 0.09538600742816924\n",
      "epoch 1 loss at step 800 is 0.1900251990556717\n",
      "epoch 1 loss at step 1600 is 0.20315280675888062\n",
      "epoch 1 loss at step 2400 is 0.2055261665582657\n",
      "epoch 1 loss at step 3200 is 0.20597144693136216\n",
      "epoch 1 loss at step 4000 is 0.2001039606332779\n",
      "epoch 1 loss at step 4800 is 0.19652952760457992\n",
      "epoch 1 loss at step 5600 is 0.20464500308036804\n",
      "epoch 1 loss at step 6400 is 0.1841752588748932\n",
      "epoch 1 loss at step 7200 is 0.21827699303627013\n",
      "epoch 1 loss at step 8000 is 0.21468355566263198\n",
      "epoch 1 loss at step 8800 is 0.2169116196036339\n",
      "epoch 1 loss at step 9600 is 0.1984374541044235\n",
      "epoch 1 loss at step 10400 is 0.2074518072605133\n",
      "epoch 1 loss at step 11200 is 0.19876446783542634\n",
      "epoch 1 loss at step 12000 is 0.20617301225662232\n",
      "epoch 1 loss at step 12800 is 0.2057680743932724\n",
      "epoch 1 loss at step 13600 is 0.21638038098812104\n",
      "epoch 1 loss at step 14400 is 0.21043752193450926\n",
      "epoch 1 loss at step 15200 is 0.22692841351032256\n",
      "epoch 1 loss at step 16000 is 0.1961502441763878\n",
      "epoch 1 loss at step 16800 is 0.183271926343441\n",
      "epoch 1 loss at step 17600 is 0.19980867385864257\n",
      "epoch 1 loss at step 18400 is 0.21670888423919676\n",
      "epoch 1 loss at step 19200 is 0.2162117052078247\n",
      "epoch 1 loss at step 20000 is 0.2075075215101242\n",
      "epoch 1 loss at step 20800 is 0.21343614012002946\n",
      "epoch 1 loss at step 21600 is 0.23518816351890565\n",
      "epoch 1 loss at step 22400 is 0.22117132782936097\n",
      "epoch 1 loss at step 23200 is 0.22434431552886963\n",
      "epoch 1 loss at step 24000 is 0.20324846506118774\n",
      "epoch 1 loss at step 24800 is 0.19904432982206344\n",
      "epoch 1 loss at step 25600 is 0.22452404081821442\n",
      "epoch 1 loss at step 26400 is 0.212058168053627\n",
      "epoch 1 loss at step 27200 is 0.21300516486167909\n",
      "epoch 1 loss at step 28000 is 0.21378070652484893\n",
      "epoch 1 loss at step 28800 is 0.2111877182126045\n",
      "epoch 1 loss at step 29600 is 0.21071794450283052\n",
      "epoch 1 loss at step 30400 is 0.22543071925640107\n",
      "epoch 1 loss at step 31200 is 0.2197836458683014\n",
      "epoch 1 loss at step 32000 is 0.20640188395977022\n",
      "epoch 1 loss at step 32800 is 0.20602605998516083\n",
      "epoch 1 loss at step 33600 is 0.21695523649454118\n",
      "epoch 1 loss at step 34400 is 0.21322002440690993\n",
      "epoch 1 loss at step 35200 is 0.21173906147480012\n",
      "epoch 1 loss at step 36000 is 0.20514254808425902\n",
      "epoch 1 loss at step 36800 is 0.22247998893260956\n",
      "epoch 1 loss at step 37600 is 0.19368003517389298\n",
      "epoch 1 loss at step 38400 is 0.2137105268239975\n",
      "epoch 1 loss at step 39200 is 0.20094828724861144\n",
      "epoch 1 loss at step 40000 is 0.2067255261540413\n",
      "epoch 1 loss at step 40800 is 0.20485610097646714\n",
      "epoch 1 loss at step 41600 is 0.21480665922164918\n",
      "epoch 1 loss at step 42400 is 0.22355650514364242\n",
      "epoch 1 loss at step 43200 is 0.23262489467859268\n",
      "epoch 1 loss at step 44000 is 0.20354790806770326\n",
      "epoch 1 loss at step 44800 is 0.2080332124233246\n",
      "epoch 1 loss at step 45600 is 0.22884201884269714\n",
      "epoch 1 loss at step 46400 is 0.2088758820295334\n",
      "epoch 1 loss at step 47200 is 0.22513927936553954\n",
      "epoch 1 loss at step 48000 is 0.20151491582393646\n",
      "epoch 1 loss at step 48800 is 0.21594372630119324\n",
      "epoch 1 loss at step 49600 is 0.22071301996707915\n",
      "epoch 1 loss at step 50400 is 0.21053805470466613\n",
      "epoch 1 loss at step 51200 is 0.22034163802862167\n",
      "epoch 1 loss at step 52000 is 0.22397880554199218\n",
      "epoch 1 loss at step 52800 is 0.19425113260746002\n",
      "epoch 1 loss at step 53600 is 0.21136915504932405\n",
      "epoch 1 loss at step 54400 is 0.20358046352863313\n",
      "epoch 1 loss at step 55200 is 0.209896320104599\n",
      "epoch 1 loss at step 56000 is 0.20149825990200043\n",
      "epoch 1 loss at step 56800 is 0.19776396840810775\n",
      "epoch 1 loss at step 57600 is 0.2192663025856018\n",
      "epoch 1 loss at step 58400 is 0.20673546850681304\n",
      "epoch 1 loss at step 59200 is 0.20224907130002975\n",
      "epoch 1 loss at step 60000 is 0.2049963194131851\n",
      "epoch 1 loss at step 60800 is 0.23183419793844223\n",
      "epoch 1 loss at step 61600 is 0.18286704272031784\n",
      "epoch 1 loss at step 62400 is 0.21365533590316774\n",
      "epoch 1 loss at step 63200 is 0.23223887056112288\n",
      "epoch 1 loss at step 64000 is 0.18979708909988402\n",
      "epoch 1 loss at step 64800 is 0.2281148463487625\n",
      "epoch 1 loss at step 65600 is 0.22157596290111542\n",
      "epoch 1 loss at step 66400 is 0.20719045758247376\n",
      "epoch 1 loss at step 67200 is 0.18929131776094438\n",
      "epoch 1 loss at step 68000 is 0.22201335459947585\n",
      "epoch 1 loss at step 68800 is 0.19653118133544922\n",
      "epoch 1 loss at step 69600 is 0.21715275168418885\n",
      "epoch 1 loss at step 70400 is 0.20119704991579057\n",
      "epoch 1 loss at step 71200 is 0.20888498514890672\n",
      "epoch 1 loss at step 72000 is 0.18796756148338317\n",
      "epoch 1 loss at step 72800 is 0.23207395255565644\n",
      "epoch 1 loss at step 73600 is 0.21235596299171447\n",
      "epoch 1 loss at step 74400 is 0.1899028342962265\n",
      "epoch 1 loss at step 75200 is 0.23373188257217406\n",
      "epoch 1 loss at step 76000 is 0.21173859238624573\n",
      "epoch 1 loss at step 76800 is 0.22679983496665954\n",
      "epoch 1 loss at step 77600 is 0.2199954232573509\n",
      "epoch 1 loss at step 78400 is 0.21214618980884553\n",
      "epoch 1 loss at step 79200 is 0.20029391318559647\n",
      "epoch 1 loss at step 80000 is 0.19477142572402953\n",
      "epoch 1 loss at step 80800 is 0.18552529096603393\n",
      "epoch 1 loss at step 81600 is 0.21953073322772979\n",
      "epoch 1 loss at step 82400 is 0.197697189450264\n",
      "epoch 1 loss at step 83200 is 0.2146019560098648\n",
      "epoch 1 loss at step 84000 is 0.20246110886335372\n",
      "epoch 1 loss at step 84800 is 0.2020081561803818\n",
      "epoch 1 loss at step 85600 is 0.19764658868312834\n",
      "epoch 1 loss at step 86400 is 0.1975672325491905\n",
      "epoch 1 loss at step 87200 is 0.23388654708862305\n",
      "epoch 1 loss at step 88000 is 0.21470425456762313\n",
      "epoch 1 loss at step 88800 is 0.19972866743803025\n",
      "epoch 1 loss at step 89600 is 0.22278160572052003\n",
      "epoch 1 loss at step 90400 is 0.19688530385494232\n",
      "epoch 1 loss at step 90752 is 0.10199403256177902\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "def train():\n",
    "    epochs = 2\n",
    "    total_loss = 0\n",
    "    log_step = 100\n",
    "    \n",
    "    print(f'Training on size: {len(train_dataset)}')\n",
    "    recommendation_model.train()\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        step_count = 0\n",
    "        for i, train_data in enumerate(train_loader):\n",
    "            users = train_data[\"users\"].to(device)\n",
    "            movies = train_data[\"movies\"].to(device)\n",
    "    \n",
    "            output = recommendation_model(users, movies)\n",
    "            output = output.squeeze()\n",
    "            \n",
    "            ratings = train_data[\"ratings\"].to(torch.float32).to(device)\n",
    "    \n",
    "            \n",
    "    \n",
    "            loss = loss_fn(output, ratings)\n",
    "            total_loss += loss.sum().item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            step_count += len(train_data[\"users\"])\n",
    "    \n",
    "            if (step_count % log_step == 0 or i == len(train_loader) - 1):\n",
    "                avg_loss = (total_loss / log_step)\n",
    "                print(f\"epoch {epoch_i} loss at step {step_count} is {avg_loss}\")\n",
    "                losses.append(avg_loss)\n",
    "                total_loss = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9077\n"
     ]
    }
   ],
   "source": [
    "  # Root Mean Squared Error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "recommendation_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, valid_data in enumerate(valid_loader):\n",
    "        model_output = recommendation_model(valid_data['users'].to(device), valid_data['movies'].to(device))\n",
    "\n",
    "        ratings = valid_data['ratings'].to(device)\n",
    "        y_true.extend(ratings.cpu().numpy()) \n",
    "        y_pred.extend(model_output.cpu().numpy())\n",
    "\n",
    "\n",
    "# actually calc RMSE\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision @ 50: 0.8907\n",
      "recall @ 50: 0.8715\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calculate_precision_recall(user_ratings, k, threshold):\n",
    "    user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "    n_rel = sum(true_r >= threshold for _, true_r in user_ratings)\n",
    "    n_rec_k = sum(est >= threshold for est, _ in user_ratings[:k])\n",
    "    n_rel_and_rec_k = sum(\n",
    "        (true_r >= threshold) and (est >= threshold) for est, true_r in user_ratings[:k]\n",
    "    )\n",
    "\n",
    "    precision = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "    recall = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "user_ratings_comparison = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for valid_data in valid_loader:\n",
    "        users = valid_data[\"users\"].to(device)\n",
    "        movies = valid_data[\"movies\"].to(device)\n",
    "        ratings = valid_data[\"ratings\"].to(device)\n",
    "        output = recommendation_model(users, movies)\n",
    "\n",
    "        for user, pred, true in zip(users, output, ratings):\n",
    "            user_ratings_comparison[user.item()].append((pred[0].item(), true.item()))\n",
    "\n",
    "user_precisions = dict()\n",
    "user_based_recalls = dict()\n",
    "\n",
    "k = 50\n",
    "threshold = 3\n",
    "\n",
    "for user_id, user_ratings in user_ratings_comparison.items():\n",
    "    precision, recall = calculate_precision_recall(user_ratings, k, threshold)\n",
    "    user_precisions[user_id] = precision\n",
    "    user_based_recalls[user_id] = recall\n",
    "\n",
    "\n",
    "    average_precision = sum(prec for prec in user_precisions.values()) / len(\n",
    "    user_precisions\n",
    ")\n",
    "average_recall = sum(rec for rec in user_based_recalls.values()) / len(\n",
    "    user_based_recalls\n",
    ")\n",
    "\n",
    "print(f\"precision @ {k}: {average_precision:.4f}\")\n",
    "print(f\"recall @ {k}: {average_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 1: [  2304 171917  26326   4610    296]\n",
      "Recommendations for user 2: [  50 1197 5974 3652 2360]\n",
      "Usual Suspects, The (1995)\n",
      "Princess Bride, The (1987)\n",
      "Thief of Bagdad, The (1940)\n",
      "City of the Living Dead (a.k.a. Gates of Hell, The) (Paura nella città dei morti viventi) (1980)\n",
      "Celebration, The (Festen) (1998)\n"
     ]
    }
   ],
   "source": [
    "def top_recommendations(user_id, all_movies, k=5, batch_size=100):\n",
    "    recommendation_model.eval()\n",
    "\n",
    "\n",
    "    \n",
    "    watched_movies = set(ratings_df[ratings_df['userId'] == user_id]['movieId'].tolist())\n",
    "    unwatched_movies = [m for m in all_movies if m not in watched_movies]\n",
    "    # fill unwatched movies\n",
    "    # for m in all_movies:\n",
    "    #     if m not in watched_movies:\n",
    "    #         unwatched_movies.append(m)\n",
    "\n",
    "    prediction = []\n",
    "    top_k_recommendations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(unwatched_movies), batch_size):\n",
    "            batched_unwatched = unwatched_movies[i:i+batch_size]\n",
    "            movie_tensor = torch.tensor(batched_unwatched).to(device)\n",
    "            user_tensor = torch.tensor([user_id] * len(batched_unwatched)).to(device)\n",
    "            prediction_model = recommendation_model(user_tensor, movie_tensor).view(-1).tolist()\n",
    "            prediction.extend(zip(batched_unwatched, prediction_model))\n",
    "\n",
    "    prediction.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for (m_id, _) in prediction[:k]:\n",
    "        top_k_recommendations.append(m_id)\n",
    "\n",
    "    # Convert this encoded movieId's back to their original ids\n",
    "    top_k_recommendations = lbl_movie.inverse_transform(top_k_recommendations)\n",
    "    \n",
    "    return top_k_recommendations\n",
    "\n",
    "# ---------------\n",
    "\n",
    "all_movies = ratings_df['movieId'].unique().tolist()\n",
    "user_id = 1\n",
    "\n",
    "recommendations = top_recommendations(user_id, all_movies, k=5)\n",
    "print(f\"Recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "user_id = 2\n",
    "recommendations = top_recommendations(user_id, all_movies, k=5)\n",
    "print(f\"Recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "for i in recommendations:\n",
    "    print(movies_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
